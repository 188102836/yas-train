{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26191748-8f87-475e-8a79-592d5f81374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "working_dir = '../yas-dump/v1.3/dumps-v1.3-4k-relabel/'\n",
    "p = Path(working_dir)\n",
    "\n",
    "df = pd.DataFrame(columns=['Label', 'IsValid', 'Position', 'DataId','ArtifactId', 'PathImageProcessed', 'PathImageRaw', 'PathLabel'],)\n",
    "\n",
    "# Read file into df\n",
    "for fpath in p.iterdir() :\n",
    "    fname = fpath.name\n",
    "    if '.txt' in fname:\n",
    "        with open(fpath, 'r') as f:\n",
    "            label = f.readline()\n",
    "            \n",
    "            raw_image_name = fname.replace('.txt', '.png')\n",
    "            processed_image_name = 'p_' + raw_image_name\n",
    "            \n",
    "            dataId = fname.removesuffix('.txt')\n",
    "            artId = int(fname.removesuffix('.txt').split('_')[-1])\n",
    "            position = '_'.join(dataId.split('_')[0:-1])\n",
    "            \n",
    "            row = {\n",
    "                'IsValid': 'Y',\n",
    "                'Label': label, \n",
    "                'PathImageProcessed': str(fpath.parent / processed_image_name), \n",
    "                'PathImageRaw': str(fpath.parent / raw_image_name), \n",
    "                'PathLabel': str(fpath),\n",
    "                'ArtifactId': artId,\n",
    "                'DataId': dataId,\n",
    "                'Position' : position,\n",
    "            }\n",
    "            \n",
    "            # 直接放弃无效数据 （不管false positive）\n",
    "            if position == 'equip':\n",
    "                if '已装备' not in label:\n",
    "                    continue\n",
    "                \n",
    "                # 跳过一些坏数据\n",
    "                if '神里绫已利已装备' in label:# 老版本中 \"珊瑚宫心海\" 在4k分辨率下会识别成这\n",
    "                    continue\n",
    "            \n",
    "            # 跳过副词条没有\"+\"的情形，这说明改副词条不存在，是词条裁切问题\n",
    "            if position in {'sub_stat_1', 'sub_stat_2', 'sub_stat_3', 'sub_stat_4'}:\n",
    "                if '+' not in label:\n",
    "                    continue\n",
    "                    \n",
    "                    \n",
    "            df = df.append(row, ignore_index=True)\n",
    "            # print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4da66de-f19c-4577-85b7-83d7c15eb477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 粗筛选\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # 去除错误的已装备\n",
    "    if row['Position'] == 'equip':\n",
    "        if '已装备' not in row['Label']:\n",
    "            row['IsValid'] = 'N'\n",
    "            \n",
    "    # 去除错误的副词条\n",
    "    if row['Position'] in {'sub_stat_1', 'sub_stat_2', 'sub_stat_3', 'sub_stat_4'}:\n",
    "        if '+' not in row['Label']:\n",
    "            row['IsValid'] = 'N'\n",
    "            \n",
    "        \n",
    "# Save df to excel\n",
    "df.to_excel('tmp.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5759c2-106a-4385-ab49-3e345337b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use openpylx to load Images to Excel\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "\n",
    "from PIL import Image as PLImage\n",
    "import PIL.ImageOps    \n",
    "\n",
    "wb = load_workbook('tmp.xlsx')\n",
    "# Get first sheet\n",
    "ws = wb.active\n",
    "\n",
    "path_column = 'G'\n",
    "\n",
    "for i in range(2, 40000):\n",
    "    path_processed_img = ws[f\"{path_column}{i}\"].value    \n",
    "    if path_processed_img:        \n",
    "        img = Image(path_processed_img)\n",
    "        ws.add_image(img, f\"A{i}\")\n",
    "\n",
    "# 导出excel，用来手工标注（修正label）\n",
    "wb.save('out.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bfd25ee-28ca-4bc6-be7c-25c00198492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取手工标注好的excel，生成dataset\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "# 读取手工标注好的excel\n",
    "df = pd.read_excel('out.xlsx')\n",
    "# df.to_csv('data-v13.csv')\n",
    "\n",
    "# Next create the data set\n",
    "dataset_name = 'realdata-labeled'\n",
    "\n",
    "def img_to_tensor(img: Image):\n",
    "    tensor = transforms.ToTensor()(img)\n",
    "    return tensor\n",
    "    \n",
    "\n",
    "# g means grayscale, b means binarized\n",
    "\n",
    "# Grayscale not supported for now, because size is not uniform\n",
    "# x_4k_g = []\n",
    "# x_900p_g = []\n",
    "\n",
    "x_4k_b = []\n",
    "x_900p_b = []\n",
    "\n",
    "y = []\n",
    "for index, row in df.iterrows():\n",
    "    # print(row['Label'])\n",
    "    y.append(row['Label'])\n",
    "    \n",
    "    # path_4k_g = row['PathImageRaw']\n",
    "    path_4k_b = row['PathImageProcessed']\n",
    "    \n",
    "    # path_900p_g = path_4k_g.replace('4k-relabel', '900p')\n",
    "    path_900p_b = path_4k_b.replace('4k-relabel', '900p')\n",
    "    \n",
    "    # tensor_4k_g = img_to_tensor(Image.open(path_4k_g))\n",
    "    # tensor_900p_g = img_to_tensor(Image.open(path_900p_g))\n",
    "    \n",
    "    tensor_4k_b = img_to_tensor(Image.open(path_4k_b))\n",
    "    tensor_900p_b = img_to_tensor(Image.open(path_900p_b))\n",
    "    \n",
    "    # x_4k_g.append(torch.unsqueeze(tensor_4k_g, dim=0))\n",
    "    # x_900p_g.append(torch.unsqueeze(tensor_900p_g, dim=0))\n",
    "    \n",
    "    x_4k_b.append(torch.unsqueeze(tensor_4k_b, dim=0))\n",
    "    x_900p_b.append(torch.unsqueeze(tensor_900p_b, dim=0))\n",
    "    \n",
    "    # print(path_900p_b)\n",
    "    \n",
    "torch.save(y, f\"{dataset_name}-label.pt\")\n",
    "\n",
    "# torch.save(torch.cat(x_4k_g, dim=0), f\"{dataset_name}-4k-g.pt\")\n",
    "# torch.save(torch.cat(x_900p_g, dim=0), f\"{dataset_name}-900p-g.pt\")\n",
    "\n",
    "torch.save(torch.cat(x_4k_b, dim=0), f\"{dataset_name}-4k-b.pt\")\n",
    "torch.save(torch.cat(x_900p_b, dim=0), f\"{dataset_name}-900p-b.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fc39ed8-107d-49ca-81c3-3e43549177a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 63, 622])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f9d183-018c-48a1-9b71-88ab6d7fe6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
